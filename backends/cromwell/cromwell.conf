# Include the default Cromwell configuration
include required(classpath("application"))

# System-wide settings for memory retry functionality
system {
  # Error strings that trigger retry with more memory
  memory-retry-error-keys = ["OutOfMemory", "Killed", "SIGKILL", "137", "out of memory"]
}

# Backend configuration
backend {
  default = SLURM
  providers {
    SLURM {
      actor-factory = "cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory"
      
      config {
        # Call caching configuration (maps to your miniwdl call_cache settings)
        call-caching {
          enabled = true
          invalidate-bad-cache-results = true
        }

        # Default runtime attributes with retry support
        runtime-attributes = """
          Int? maxRetries = 2
          String? docker = "ubuntu:20.04"
          String shell = "/bin/bash"
          Int runtime_minutes = 600
          Int cpu = 2
          String memory = "8G"
          String? partition = "cpu"
          String? account
        """

        # SLURM submit command with Singularity integration
        submit = """
          # Set Singularity cache directory
          export SINGULARITY_CACHEDIR=/hpc/scratch/group.data.science/ram_temp/HiFi-human-WGS-editing-QC-WDL/miniwdl_cache/singularity_cache
          export SINGULARITY_TMPDIR=${SINGULARITY_CACHEDIR}/tmp
          mkdir -p ${SINGULARITY_CACHEDIR}/tmp
          
          # Convert memory format if needed (e.g., "8G" -> "8000M")
          MEMORY_MB=$(echo "${memory}" | sed 's/G$/*1024/' | sed 's/M$//' | bc)
          
          sbatch \
            --partition=${default="cpu" partition} \
            --comment='cromwell job' \
            -J ${job_name} \
            -D ${cwd} \
            -o ${cwd}/execution/stdout \
            -e ${cwd}/execution/stderr \
            -t ${runtime_minutes} \
            -c ${cpu} \
            --mem=${memory} \
            ${true="--account=" + account false="" defined(account)} \
            --wrap "singularity exec --containall --nv --bind ${cwd}:${cwd} ${SINGULARITY_CACHEDIR}/$(echo ${docker} | tr '/:.' '_').sif ${shell} ${script}"
        """

        kill = "scancel ${job_id}"
        check-alive = "squeue -j ${job_id}"
        job-id-regex = "Submitted batch job (\\d+).*"

        # Working directory configuration
        root = "$PWD"
        dockerRoot = "/cromwell-executions"
        
        # Concurrency limit (maps to task_concurrency in miniwdl)
        concurrent-job-limit = 200
        
        # Filesystem configuration
        filesystems {
          local {
            localization: ["copy", "hard-link", "soft-link"]
            caching {
              duplication-strategy: ["copy", "hard-link", "soft-link"]
              # Use xxh64 for faster hashing (equivalent to miniwdl performance)
              hashing-strategy: "xxh64"
            }
          }
        }

        # Exit code timeout (helps with hung jobs)
        exit-code-timeout-seconds = 3600
      }
    }
  }
}

# Database configuration for call caching persistence
database {
  profile = "slick.jdbc.HsqldbProfile$"
  db {
    driver = "org.hsqldb.jdbcDriver"
    url = "jdbc:hsqldb:file:/hpc/scratch/group.data.science/ram_temp/HiFi-human-WGS-editing-QC-WDL/miniwdl_cache/cromwell_db/cromwell_db;shutdown=false;hsqldb.tx=mvcc"
    connectionTimeout = 120000
    numThreads = 1
  }
}

# Call caching configuration
call-caching {
  enabled = true
  invalidate-bad-cache-results = true
}

# Webservice configuration (optional - for server mode)
webservice {
  port = 8000
  interface = "127.0.0.1"
}

# Akka configuration for large workflows
akka {
  http {
    server {
      request-timeout = 3600s
      idle-timeout = 3600s
    }
  }
}
